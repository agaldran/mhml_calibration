{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def set_seed(seed_value, use_cuda):\n",
    "    if seed_value is not None:\n",
    "        np.random.seed(seed_value)  # cpu vars\n",
    "        torch.manual_seed(seed_value)  # cpu  vars\n",
    "        random.seed(seed_value)  # Python\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(seed_value)\n",
    "            torch.cuda.manual_seed_all(seed_value)\n",
    "            torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, argparse, os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import medmnist\n",
    "from utils.data_handling import get_medmnist_loaders, get_medmnist_test_loader\n",
    "from utils.data_handling import get_class_loaders, get_class_test_loader\n",
    "from utils.evaluation import evaluate_cls\n",
    "from utils.get_model_v2 import get_arch\n",
    "from tqdm import trange, tqdm\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "from utils.data_handling import get_class_test_loader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import log_loss as error\n",
    "\n",
    "# from utils.temperature_calibration import ModelWithTemperature\n",
    "from utils.data_handling import get_medmnist_loaders\n",
    "from sklearn.metrics import balanced_accuracy_score as balacc\n",
    "from sklearn.metrics import matthews_corrcoef as mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f432dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    probs_all, labels_all = [], []\n",
    "\n",
    "    for i_batch, (inputs, labels) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        logits = model(inputs)  # bs x n_classes\n",
    "        probs = logits.softmax(dim=1).detach().cpu().numpy()\n",
    "        labels = labels.numpy()\n",
    "        if labels.ndim == 0:  # for 1-element batches labels degenerates to a scalar\n",
    "            labels = np.expand_dims(labels, 0)\n",
    "        probs_all.extend(probs)\n",
    "        labels_all.extend(list(labels))\n",
    "\n",
    "    return np.stack(probs_all), np.array(labels_all).squeeze()\n",
    "\n",
    "def test_cls(model, test_loader, device):\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        probs, labels = test_one_epoch(model, test_loader, device)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b931c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch_multihead(model, loader, device):\n",
    "    ## IMPORTANT: Note that multi-head models in test time return softmax-activated tensors and not logits\n",
    "    ## which is shitty because I cannot apply TS directly\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    probs_all, labels_all = [], []\n",
    "\n",
    "    for i_batch, (inputs, labels) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        probs = model(inputs).detach().cpu().numpy()\n",
    "\n",
    "        labels = labels.numpy()\n",
    "        if labels.ndim == 0:  # for 1-element batches labels degenerates to a scalar\n",
    "            labels = np.expand_dims(labels, 0)\n",
    "        probs_all.extend(probs)\n",
    "        labels_all.extend(list(labels))\n",
    "\n",
    "    return np.stack(probs_all), np.array(labels_all).squeeze()\n",
    "\n",
    "def test_cls_multihead(model, test_loader, device):\n",
    "    with torch.inference_mode():\n",
    "        probs, labels = test_one_epoch_multihead(model, test_loader, device)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_multi_fold(dataset=None, model_name='convnext', n_bins=15, method='sl1h', with_ens=False):\n",
    "    assert dataset is not None\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    seed=0\n",
    "    set_seed(seed, use_cuda)\n",
    "    if model_name in ['convnext', 'swin'] :\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    assert dataset in ['chaoyang', 'kvasir', 'pathmnist']\n",
    "\n",
    "    if dataset=='pathmnist':\n",
    "        tg_size = 28 if model_name !='convnext' else 32\n",
    "        test_loader = get_medmnist_test_loader(dataset, batch_size=128, num_workers=6, tg_size=tg_size)\n",
    "        class_names = list(medmnist.INFO[dataset]['label'].keys())\n",
    "        num_classes = len(class_names)\n",
    "            \n",
    "    else:\n",
    "        data_path = osp.join('data', dataset)\n",
    "        csv_test = osp.join('data', 'test_'+dataset+'.csv')\n",
    "        tg_size = 224,224\n",
    "        test_loader  = get_class_test_loader(csv_test, data_path, tg_size, batch_size=64, num_workers=6)\n",
    "        num_classes = len(test_loader.dataset.classes)\n",
    "        \n",
    "    load_path = osp.join('experiments', dataset, method)\n",
    "    \n",
    "    ########################\n",
    "    # results for individual models\n",
    "    ########################    \n",
    "    if model_name=='convnext':\n",
    "        load_path_this = osp.join(load_path, 'cnx_f')        \n",
    "    elif model_name=='resnet50':\n",
    "        load_path_this = osp.join(load_path, 'r50_f')\n",
    "    elif model_name=='swin':\n",
    "        load_path_this = osp.join(load_path, 'swt_f')\n",
    "    model = get_arch(model_name, num_classes)\n",
    "    checkpoint_list = [osp.join(load_path_this + str(i), 'model_checkpoint.pth') for i in [0, 1, 2, 3, 4]]\n",
    "    states = [torch.load(c,  map_location=device) for c in checkpoint_list]\n",
    "    \n",
    "    all_probs = []\n",
    "    # Do inference for each model\n",
    "    with torch.inference_mode():\n",
    "        for i in range(len(states)):\n",
    "            state=states[i]\n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "            probs, labels = test_cls(model, test_loader, device)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    ece = MulticlassCalibrationError(num_classes=num_classes, n_bins=n_bins, norm='l1')\n",
    "    \n",
    "\n",
    "    accs, eces, ces= [],[],[]\n",
    "    for probs in all_probs:\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, preds, probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(probs), torch.from_numpy(labels)).item()        \n",
    "        ce = log_loss(labels,probs)\n",
    "        \n",
    "        accs.append(100*test_acc)\n",
    "        eces.append(100*e)\n",
    "        ces.append(100*ce)\n",
    " \n",
    "    ########################\n",
    "    # print average results\n",
    "    ######################## \n",
    "    print('ACC={:.2f}+/-{:.2f}, ECE={:.2f}+/-{:.2f}, NLL={:.2f}+/-{:.2f}'.format(\n",
    "        np.mean(accs), np.std(accs), np.mean(eces), np.std(eces), np.mean(ces), np.std(ces)))\n",
    "\n",
    "    if with_ens:\n",
    "        ########################\n",
    "        # results for ensemble\n",
    "        ########################  \n",
    "        ens_probs = np.mean(all_probs, axis=0)\n",
    "        ens_preds = np.argmax(ens_probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, ens_preds, ens_probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(ens_probs), torch.from_numpy(labels)).item()\n",
    "        ce = log_loss(labels,ens_probs)\n",
    "\n",
    "        print(30*'-')\n",
    "        print('DEEP ENSEMBLES:')\n",
    "        print('AUC={:.2f}, ACC={:.2f}, ECE={:.2f}, NLL={:.2f}'.format(100*test_acc,100*e,100*ce))\n",
    "        \n",
    "    mtrcs = [np.mean(accs), np.mean(eces), np.mean(ces), \n",
    "             np.std(accs),  np.std(eces),  np.std(ces)]\n",
    "\n",
    "    if with_ens:\n",
    "        return mtrcs, [100*test_acc, 100*e, 100*ce]\n",
    "    return mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e366dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_multi_head(dataset=None, model_name='convnext', method='4lmh', n_bins=15, nh=2):\n",
    "    assert dataset is not None\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    # reproducibility\n",
    "    seed=0\n",
    "    set_seed(seed, use_cuda)\n",
    "    if model_name in ['convnext', 'swin'] :\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    assert dataset in ['chaoyang', 'kvasir', 'pathmnist']\n",
    "    \n",
    "\n",
    "    if dataset=='pathmnist':\n",
    "        tg_size = 28 if model_name !='convnext' else 32\n",
    "        test_loader = get_medmnist_test_loader(dataset, batch_size=128, num_workers=6, tg_size=tg_size)\n",
    "        class_names = list(medmnist.INFO[dataset]['label'].keys())\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "    else:\n",
    "        data_path = osp.join('data', dataset)\n",
    "        csv_test = osp.join('data', 'test_'+dataset+'.csv')\n",
    "        tg_size = 224,224   \n",
    "        test_loader  = get_class_test_loader(csv_test, data_path, tg_size, batch_size=64, num_workers=6)\n",
    "        num_classes = len(test_loader.dataset.classes)\n",
    "        class_names = ['C{}_probs'.format(i) for i in range(num_classes)]\n",
    "\n",
    "    \n",
    "    load_path = osp.join('experiments', dataset, method)\n",
    "    if '2h' in method: nh = 2\n",
    "    elif '4h' in method: nh = 4\n",
    "    else: return 'need multi-head model here'\n",
    "    \n",
    "    if model_name=='convnext':\n",
    "        load_path_this = osp.join(load_path, 'cnx_f')\n",
    "    elif model_name=='resnet50':\n",
    "        load_path_this = osp.join(load_path, 'r50_f')\n",
    "    elif model_name=='swin':\n",
    "        load_path_this = osp.join(load_path, 'swt_f')\n",
    "\n",
    "    ########################\n",
    "    # results for multi-head\n",
    "    ########################\n",
    "    model = get_arch(model_name, num_classes, n_heads=nh)\n",
    "    checkpoint_list = [osp.join(load_path_this + str(i), 'model_checkpoint.pth') for i in [0, 1, 2, 3, 4]]\n",
    "    states = [torch.load(c,  map_location=device) for c in checkpoint_list]\n",
    "    all_probs = []\n",
    "    # Do inference on val data\n",
    "    with torch.inference_mode():\n",
    "        for i in range(len(states)):\n",
    "            state=states[i]        \n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "            probs, labels = test_cls_multihead(model, test_loader, device)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    ece = MulticlassCalibrationError(num_classes=num_classes, n_bins=15, norm='l1')\n",
    "\n",
    "    \n",
    "    accs, eces, ces= [],[],[]\n",
    "    for probs in all_probs:\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, preds, probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(probs), torch.from_numpy(labels)).item()\n",
    "        ce = log_loss(labels,probs)                \n",
    "        accs.append(100*test_acc)\n",
    "        eces.append(100*e)\n",
    "        ces.append(100*ce)\n",
    "        \n",
    "    ########################\n",
    "    # print average results\n",
    "    ######################## \n",
    "    print('ACC={:.2f}+/-{:.2f}, ECE={:.2f}+/-{:.2f}, NLL={:.2f}+/-{:.2f}'.format(\n",
    "    np.mean(accs), np.std(accs), np.mean(eces), np.std(eces), np.mean(ces), np.std(ces)))\n",
    "    \n",
    "    mtrcs = [np.mean(accs), np.mean(eces), np.mean(ces), \n",
    "             np.std(accs),  np.std(eces),  np.std(ces)]\n",
    "    return mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(dataset, model_name):\n",
    "    metrcs = dict()\n",
    "    print(60*'=')\n",
    "    print('Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "\n",
    "    metrcs['sl1h'], metrcs['ens'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, with_ens=True)\n",
    "\n",
    "    # LS\n",
    "    print('\\n')\n",
    "    print(60*'=')\n",
    "    print('LS gamma=0.05: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['ls_005'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='ls_005', with_ens=False)\n",
    "\n",
    "    # MbLS\n",
    "    print('\\n')\n",
    "    print(60*'=')\n",
    "    print('MbLS m=6: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['mbls_6'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='mbls_6', with_ens=False)\n",
    "    \n",
    "    # MIXUP\n",
    "    print('\\n')   \n",
    "    print(60*'=')\n",
    "    print('MixUp gamma=0.2: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['mxp_02'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='mxp_02', with_ens=False)\n",
    "\n",
    "    # DCA\n",
    "    print('\\n')   \n",
    "    print(60*'=')\n",
    "    print('DCA: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['dca'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='dca', with_ens=False)\n",
    "\n",
    "    # 2hsl\n",
    "    print('\\n') \n",
    "    print(60*'=')\n",
    "    print('2hsl')\n",
    "    print(60*'=')\n",
    "    metrcs['2hsl'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='2hsl')\n",
    "\n",
    "    # 2hml\n",
    "    print(60*'*')\n",
    "    print('2hml')\n",
    "    print(60*'*')\n",
    "    metrcs['2hml'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='2hml')\n",
    "\n",
    "    # 4hml   \n",
    "    print(60*'*')\n",
    "    print('4hml')\n",
    "    print(60*'*')\n",
    "    metrcs['4hml'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='4hml')\n",
    "    \n",
    "    return metrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28407df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows(col_model_dict, col1, col2, col3, col4, s1, s2, s3, strings):\n",
    "    sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings\n",
    "    a, b, c = 0, 1, 2\n",
    "    x, y, z = 3, 4, 5\n",
    "    sl1h_str=sl1h_str.replace(col1, '{:.2f}'.format(col_model_dict['sl1h'][a]))\n",
    "    sl1h_str=sl1h_str.replace(col2, '{:.2f}'.format(col_model_dict['sl1h'][b]))\n",
    "    sl1h_str=sl1h_str.replace(col3,  '{:.2f}'.format(col_model_dict['sl1h'][c]))\n",
    "    sl1h_str=sl1h_str.replace(col4,  '{:.1f}'.format(col_model_dict['sl1h'][-1]))\n",
    "    sl1h_str=sl1h_str.replace(s1, '{:.2f}'.format(col_model_dict['sl1h'][x]))\n",
    "    sl1h_str=sl1h_str.replace(s2, '{:.2f}'.format(col_model_dict['sl1h'][y]))\n",
    "    sl1h_str=sl1h_str.replace(s3,  '{:.2f}'.format(col_model_dict['sl1h'][z]))\n",
    "    \n",
    "    DE_str=DE_str.replace(col1, '{:.2f}'.format(col_model_dict['ens'][a]))\n",
    "    DE_str=DE_str.replace(col2, '{:.2f}'.format(col_model_dict['ens'][b]))\n",
    "    DE_str=DE_str.replace(col3,  '{:.2f}'.format(col_model_dict['ens'][c]))\n",
    "    DE_str=DE_str.replace(col4,  '{:.1f}'.format(col_model_dict['ens'][-1]))\n",
    "\n",
    "    LS_str=LS_str.replace(col1, '{:.2f}'.format(col_model_dict['ls_005'][a]))\n",
    "    LS_str=LS_str.replace(col2, '{:.2f}'.format(col_model_dict['ls_005'][b]))\n",
    "    LS_str=LS_str.replace(col3,  '{:.2f}'.format(col_model_dict['ls_005'][c]))\n",
    "    LS_str=LS_str.replace(col4,  '{:.1f}'.format(col_model_dict['ls_005'][-1]))\n",
    "    LS_str=LS_str.replace(s1, '{:.2f}'.format(col_model_dict['ls_005'][x]))\n",
    "    LS_str=LS_str.replace(s2, '{:.2f}'.format(col_model_dict['ls_005'][y]))\n",
    "    LS_str=LS_str.replace(s3,  '{:.2f}'.format(col_model_dict['ls_005'][z]))    \n",
    "\n",
    "    MbLS_str=MbLS_str.replace(col1, '{:.2f}'.format(col_model_dict['mbls_6'][a]))\n",
    "    MbLS_str=MbLS_str.replace(col2, '{:.2f}'.format(col_model_dict['mbls_6'][b]))\n",
    "    MbLS_str=MbLS_str.replace(col3,  '{:.2f}'.format(col_model_dict['mbls_6'][c]))\n",
    "    MbLS_str=MbLS_str.replace(col4,  '{:.1f}'.format(col_model_dict['mbls_6'][-1]))\n",
    "    MbLS_str=MbLS_str.replace(s1, '{:.2f}'.format(col_model_dict['mbls_6'][x]))\n",
    "    MbLS_str=MbLS_str.replace(s2, '{:.2f}'.format(col_model_dict['mbls_6'][y]))\n",
    "    MbLS_str=MbLS_str.replace(s3,  '{:.2f}'.format(col_model_dict['mbls_6'][z]))   \n",
    "    \n",
    "    Mxp_str=Mxp_str.replace(col1, '{:.2f}'.format(col_model_dict['mxp_02'][a]))\n",
    "    Mxp_str=Mxp_str.replace(col2, '{:.2f}'.format(col_model_dict['mxp_02'][b]))\n",
    "    Mxp_str=Mxp_str.replace(col3,  '{:.2f}'.format(col_model_dict['mxp_02'][c]))\n",
    "    Mxp_str=Mxp_str.replace(col4,  '{:.1f}'.format(col_model_dict['mxp_02'][-1]))\n",
    "    Mxp_str=Mxp_str.replace(s1, '{:.2f}'.format(col_model_dict['mxp_02'][x]))\n",
    "    Mxp_str=Mxp_str.replace(s2, '{:.2f}'.format(col_model_dict['mxp_02'][y]))\n",
    "    Mxp_str=Mxp_str.replace(s3,  '{:.2f}'.format(col_model_dict['mxp_02'][z]))   \n",
    "    \n",
    "    DCA_str=DCA_str.replace(col1, '{:.2f}'.format(col_model_dict['dca'][a]))\n",
    "    DCA_str=DCA_str.replace(col2, '{:.2f}'.format(col_model_dict['dca'][b]))\n",
    "    DCA_str=DCA_str.replace(col3,  '{:.2f}'.format(col_model_dict['dca'][c]))\n",
    "    DCA_str=DCA_str.replace(col4,  '{:.1f}'.format(col_model_dict['dca'][-1]))\n",
    "    DCA_str=DCA_str.replace(s1, '{:.2f}'.format(col_model_dict['dca'][x]))\n",
    "    DCA_str=DCA_str.replace(s2, '{:.2f}'.format(col_model_dict['dca'][y]))\n",
    "    DCA_str=DCA_str.replace(s3,  '{:.2f}'.format(col_model_dict['dca'][z]))   \n",
    "    \n",
    "    h2sl_str=h2sl_str.replace(col1, '{:.2f}'.format(col_model_dict['h2sl'][a]))\n",
    "    h2sl_str=h2sl_str.replace(col2, '{:.2f}'.format(col_model_dict['h2sl'][b]))\n",
    "    h2sl_str=h2sl_str.replace(col3,  '{:.2f}'.format(col_model_dict['h2sl'][c]))\n",
    "    h2sl_str=h2sl_str.replace(col4,  '{:.1f}'.format(col_model_dict['h2sl'][-1]))\n",
    "    h2sl_str=h2sl_str.replace(s1, '{:.2f}'.format(col_model_dict['h2sl'][x]))\n",
    "    h2sl_str=h2sl_str.replace(s2, '{:.2f}'.format(col_model_dict['h2sl'][y]))\n",
    "    h2sl_str=h2sl_str.replace(s3,  '{:.2f}'.format(col_model_dict['h2sl'][z]))  \n",
    "    \n",
    "    h2ml_str=h2ml_str.replace(col1, '{:.2f}'.format(col_model_dict['h2ml'][a]))\n",
    "    h2ml_str=h2ml_str.replace(col2, '{:.2f}'.format(col_model_dict['h2ml'][b]))\n",
    "    h2ml_str=h2ml_str.replace(col3,  '{:.2f}'.format(col_model_dict['h2ml'][c]))\n",
    "    h2ml_str=h2ml_str.replace(col4,  '{:.1f}'.format(col_model_dict['h2ml'][-1]))\n",
    "    h2ml_str=h2ml_str.replace(s1, '{:.2f}'.format(col_model_dict['h2ml'][x]))\n",
    "    h2ml_str=h2ml_str.replace(s2, '{:.2f}'.format(col_model_dict['h2ml'][y]))\n",
    "    h2ml_str=h2ml_str.replace(s3,  '{:.2f}'.format(col_model_dict['h2ml'][z]))\n",
    "    \n",
    "    h4ml_str=h4ml_str.replace(col1, '{:.2f}'.format(col_model_dict['h4ml'][a]))\n",
    "    h4ml_str=h4ml_str.replace(col2, '{:.2f}'.format(col_model_dict['h4ml'][b]))\n",
    "    h4ml_str=h4ml_str.replace(col3,  '{:.2f}'.format(col_model_dict['h4ml'][c])) \n",
    "    h4ml_str=h4ml_str.replace(col4,  '{:.1f}'.format(col_model_dict['h4ml'][-1])) \n",
    "    h4ml_str=h4ml_str.replace(s1, '{:.2f}'.format(col_model_dict['h4ml'][x]))\n",
    "    h4ml_str=h4ml_str.replace(s2, '{:.2f}'.format(col_model_dict['h4ml'][y]))\n",
    "    h4ml_str=h4ml_str.replace(s3,  '{:.2f}'.format(col_model_dict['h4ml'][z]))   \n",
    "    \n",
    "    return sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7901fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_acc_ece_nll_combined_ranks(dic):\n",
    "    dic_acc = {key:value[0] for (key,value) in dic.items()} #acc\n",
    "    # False for lower is better, True for higher is better\n",
    "    dic_rank_acc = {key: rank for rank, key in enumerate(sorted(dic_acc, key=dic_acc.get, reverse=True), 1)}\n",
    "       \n",
    "    dic_ece = {key:value[1] for (key,value) in dic.items()}\n",
    "    dic_rank_ece = {key: rank for rank, key in enumerate(sorted(dic_ece, key=dic_ece.get, reverse=False), 1)}\n",
    "\n",
    "    dic_nll = {key:value[2] for (key,value) in dic.items()}\n",
    "    # False for lower is better, True for higher is better\n",
    "    dic_rank_nll = {key: rank for rank, key in enumerate(sorted(dic_nll, key=dic_nll.get, reverse=False), 1)}\n",
    "\n",
    "    \n",
    "    for key in dic:\n",
    "        dic[key].extend([dic_rank_acc[key], dic_rank_ece[key], dic_rank_nll[key],\n",
    "                         np.mean([dic_rank_acc[key], dic_rank_ece[key], dic_rank_nll[key]])])    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f240adf",
   "metadata": {},
   "source": [
    "# CHAOYANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='chaoyang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104adccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_r50 = \\\n",
    "print_all(dataset, 'resnet50') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f798f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_cvx = \\\n",
    "print_all(dataset, 'convnext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8aade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_swt = \\\n",
    "print_all(dataset, 'swin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f488535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_r18_with_ranks = add_acc_ece_combined_ranks(m_r18)\n",
    "m_r50_with_ranks = add_acc_ece_nll_combined_ranks(m_r50)\n",
    "m_cvx_with_ranks = add_acc_ece_nll_combined_ranks(m_cvx)\n",
    "m_swt_with_ranks = add_acc_ece_nll_combined_ranks(m_swt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec13ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl1h_str  ='\\\\textbf{SL1H}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DE_str    ='\\\\textbf{D-Ens}    & xx1 & xx2 & xx3 & xx4 & xx5 & xx6 & xx7 & xx8 & xx9 & x10 & x11 & x12 \\\\\\\\'\n",
    "LS_str    ='\\\\textbf{LS}       & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "MbLS_str  ='\\\\textbf{MbLS}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "Mxp_str   ='\\\\textbf{MixUp}    & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DCA_str   ='\\\\textbf{DCA}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2sl_str  ='\\\\textbf{2HSL}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2ml_str   ='\\\\textbf{2HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h4ml_str   ='\\\\textbf{4HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22276ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str]\n",
    "\n",
    "strings = fill_rows(m_r50, 'xx1', 'xx2', 'xx3', 'xx4', 'ss1', 'ss2', 'ss3', strings)\n",
    "strings = fill_rows(m_cvx, 'xx5', 'xx6', 'xx7', 'xx8', 'ss5', 'ss6', 'ss7', strings)\n",
    "strings = fill_rows(m_swt, 'xx9', 'x10', 'x11', 'x12', 'ss9', 's10', 's11', strings)\n",
    "\n",
    "sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ec708",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = r'\\caption{Results on the \\textbf{Chaoyang dataset} , with standard deviation for 5 training runs.\\\n",
    "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{chaoyang_dispersion}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632907f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\\\begin{sidewaystable}')\n",
    "print('\\\\renewcommand{\\\\arraystretch}{1.03}')\n",
    "print('\\\\setlength\\\\tabcolsep{1.00pt}')\n",
    "print('\\\\centering')\n",
    "print(caption)\n",
    "print('\\\\smallskip')\n",
    "print('\\\\begin{tabular}{c cccc cccc cccc}')\n",
    "print('& \\\\multicolumn{4}{c}{\\\\textbf{ResNet50}} & \\\\multicolumn{4}{c}{\\\\textbf{ConvNeXt}} & \\\\multicolumn{4}{c}{\\\\textbf{Swin-Transformer}} \\\\\\\\')\n",
    "print('\\\\cmidrule(lr){2-5} \\\\cmidrule(lr){6-9} \\\\cmidrule(lr){10-13} &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$  &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$    &  ACC$^\\\\uparrow$ &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$\\\\\\\\')\n",
    "print('\\\\midrule')\n",
    "print(sl1h_str)\n",
    "print('\\midrule')\n",
    "print(LS_str)\n",
    "print('\\midrule')\n",
    "print(MbLS_str)\n",
    "print('\\midrule')\n",
    "print(Mxp_str)\n",
    "print('\\midrule')\n",
    "print(DCA_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(DE_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(h2sl_str)\n",
    "print('\\midrule')\n",
    "print(h2ml_str)\n",
    "print('\\midrule')\n",
    "print(h4ml_str)\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\\\[-0.25cm]')\n",
    "print('\\\\end{tabular}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5947720",
   "metadata": {},
   "source": [
    "# Kvasir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0185a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='kvasir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d3e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_cvx = \\\n",
    "print_all(dataset, 'convnext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796561c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_r50 = \\\n",
    "print_all(dataset, 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2741ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_swt = \\\n",
    "print_all(dataset, 'swin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_r50_with_ranks = add_acc_ece_nll_combined_ranks(m_r50)\n",
    "m_cvx_with_ranks = add_acc_ece_nll_combined_ranks(m_cvx)\n",
    "m_swt_with_ranks = add_acc_ece_nll_combined_ranks(m_swt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl1h_str  ='\\\\textbf{SL1H}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DE_str    ='\\\\textbf{D-Ens}    & xx1 & xx2 & xx3 & xx4 & xx5 & xx6 & xx7 & xx8 & xx9 & x10 & x11 & x12 \\\\\\\\'\n",
    "LS_str    ='\\\\textbf{LS}       & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "MbLS_str  ='\\\\textbf{MbLS}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "Mxp_str   ='\\\\textbf{MixUp}    & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DCA_str   ='\\\\textbf{DCA}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2sl_str  ='\\\\textbf{2HSL}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2ml_str   ='\\\\textbf{2HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h4ml_str   ='\\\\textbf{4HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84294e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str]\n",
    "\n",
    "strings = fill_rows(m_r50, 'xx1', 'xx2', 'xx3', 'xx4', 'ss1', 'ss2', 'ss3', strings)\n",
    "strings = fill_rows(m_cvx, 'xx5', 'xx6', 'xx7', 'xx8', 'ss5', 'ss6', 'ss7', strings)\n",
    "strings = fill_rows(m_swt, 'xx9', 'x10', 'x11', 'x12', 'ss9', 's10', 's11', strings)\n",
    "\n",
    "sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = r'\\caption{Results on the \\textbf{Kvasir dataset} , with standard deviation for 5 training runs.\\\n",
    "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{kvasir_dispersion}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8e8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\\\bigskip\\\\bigskip  % provide some separation between the two tables')\n",
    "print(caption)\n",
    "print('\\\\smallskip')\n",
    "print('\\\\smallskip')\n",
    "print('\\\\begin{tabular}{c cccc cccc cccc}')\n",
    "print('& \\\\multicolumn{4}{c}{\\\\textbf{ResNet50}} & \\\\multicolumn{4}{c}{\\\\textbf{ConvNeXt}} & \\\\multicolumn{4}{c}{\\\\textbf{Swin-Transformer}} \\\\\\\\')\n",
    "print('\\\\cmidrule(lr){2-5} \\\\cmidrule(lr){6-9} \\\\cmidrule(lr){10-13} &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$  &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$    &  ACC$^\\\\uparrow$ &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$\\\\\\\\')\n",
    "print('\\\\midrule')\n",
    "print(sl1h_str)\n",
    "print('\\midrule')\n",
    "print(LS_str)\n",
    "print('\\midrule')\n",
    "print(MbLS_str)\n",
    "print('\\midrule')\n",
    "print(Mxp_str)\n",
    "print('\\midrule')\n",
    "print(DCA_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(DE_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(h2sl_str)\n",
    "print('\\midrule')\n",
    "print(h2ml_str)\n",
    "print('\\midrule')\n",
    "print(h4ml_str)\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\\\[-0.25cm]')\n",
    "print('\\\\end{tabular}')\n",
    "print('\\\\end{sidewaystable}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
