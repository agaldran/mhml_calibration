{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ffd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdb2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def set_seed(seed_value, use_cuda):\n",
    "    if seed_value is not None:\n",
    "        np.random.seed(seed_value)  # cpu vars\n",
    "        torch.manual_seed(seed_value)  # cpu  vars\n",
    "        random.seed(seed_value)  # Python\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(seed_value)\n",
    "            torch.cuda.manual_seed_all(seed_value)\n",
    "            torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cead3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, argparse, os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import medmnist\n",
    "from utils.data_handling import get_medmnist_loaders, get_medmnist_test_loader\n",
    "from utils.data_handling import get_class_loaders, get_class_test_loader\n",
    "from utils.evaluation import evaluate_cls\n",
    "from utils.get_model_v2 import get_arch\n",
    "from tqdm import trange, tqdm\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354f9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "from utils.data_handling import get_class_test_loader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import log_loss as error\n",
    "\n",
    "# from utils.temperature_calibration import ModelWithTemperature\n",
    "from utils.data_handling import get_medmnist_loaders\n",
    "from sklearn.metrics import balanced_accuracy_score as balacc\n",
    "from sklearn.metrics import matthews_corrcoef as mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f432dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    probs_all, labels_all = [], []\n",
    "\n",
    "    for i_batch, (inputs, labels) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        logits = model(inputs)  # bs x n_classes\n",
    "        probs = logits.softmax(dim=1).detach().cpu().numpy()\n",
    "        labels = labels.numpy()\n",
    "        if labels.ndim == 0:  # for 1-element batches labels degenerates to a scalar\n",
    "            labels = np.expand_dims(labels, 0)\n",
    "        probs_all.extend(probs)\n",
    "        labels_all.extend(list(labels))\n",
    "\n",
    "    return np.stack(probs_all), np.array(labels_all).squeeze()\n",
    "\n",
    "def test_cls(model, test_loader, device):\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        probs, labels = test_one_epoch(model, test_loader, device)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b931c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch_multihead(model, loader, device):\n",
    "    ## IMPORTANT: Note that multi-head models in test time return softmax-activated tensors and not logits\n",
    "    ## which is shitty because I cannot apply TS directly\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    probs_all, labels_all = [], []\n",
    "\n",
    "    for i_batch, (inputs, labels) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        probs = model(inputs).detach().cpu().numpy()\n",
    "\n",
    "        labels = labels.numpy()\n",
    "        if labels.ndim == 0:  # for 1-element batches labels degenerates to a scalar\n",
    "            labels = np.expand_dims(labels, 0)\n",
    "        probs_all.extend(probs)\n",
    "        labels_all.extend(list(labels))\n",
    "\n",
    "    return np.stack(probs_all), np.array(labels_all).squeeze()\n",
    "\n",
    "def test_cls_multihead(model, test_loader, device):\n",
    "    with torch.inference_mode():\n",
    "        probs, labels = test_one_epoch_multihead(model, test_loader, device)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224f5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5fca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7528cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a0581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_multi_fold(dataset=None, model_name='convnext', n_bins=15, method='sl1h', with_ens=False):\n",
    "    assert dataset is not None\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    seed=0\n",
    "    set_seed(seed, use_cuda)\n",
    "    if model_name in ['convnext', 'swin'] :\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    assert dataset in ['chaoyang', 'kvasir', 'pathmnist']\n",
    "\n",
    "    if dataset=='pathmnist':\n",
    "        tg_size = 28 if model_name !='convnext' else 32\n",
    "        test_loader = get_medmnist_test_loader(dataset, batch_size=128, num_workers=6, tg_size=tg_size)\n",
    "        class_names = list(medmnist.INFO[dataset]['label'].keys())\n",
    "        num_classes = len(class_names)\n",
    "            \n",
    "    else:\n",
    "        data_path = osp.join('data', dataset)\n",
    "        csv_test = osp.join('data', 'test_'+dataset+'.csv')\n",
    "        tg_size = 224,224\n",
    "        test_loader  = get_class_test_loader(csv_test, data_path, tg_size, batch_size=64, num_workers=6)\n",
    "        num_classes = len(test_loader.dataset.classes)\n",
    "        \n",
    "    load_path = osp.join('experiments', dataset, method)\n",
    "    \n",
    "    ########################\n",
    "    # results for individual models\n",
    "    ########################    \n",
    "    if model_name=='convnext':\n",
    "        load_path_this = osp.join(load_path, 'cnx_f')        \n",
    "    elif model_name=='resnet50':\n",
    "        load_path_this = osp.join(load_path, 'r50_f')\n",
    "    elif model_name=='swin':\n",
    "        load_path_this = osp.join(load_path, 'swt_f')\n",
    "    model = get_arch(model_name, num_classes)\n",
    "    checkpoint_list = [osp.join(load_path_this + str(i), 'model_checkpoint.pth') for i in [0, 1, 2, 3, 4]]\n",
    "    states = [torch.load(c,  map_location=device) for c in checkpoint_list]\n",
    "    \n",
    "    all_probs = []\n",
    "    # Do inference for each model\n",
    "    with torch.inference_mode():\n",
    "        for i in range(len(states)):\n",
    "            state=states[i]\n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "            probs, labels = test_cls(model, test_loader, device)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    ece = MulticlassCalibrationError(num_classes=num_classes, n_bins=n_bins, norm='l1')\n",
    "    \n",
    "\n",
    "    accs, eces, ces= [],[],[]\n",
    "    for probs in all_probs:\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, preds, probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(probs), torch.from_numpy(labels)).item()        \n",
    "        ce = log_loss(labels,probs)\n",
    "        \n",
    "        accs.append(100*test_acc)\n",
    "        eces.append(100*e)\n",
    "        ces.append(100*ce)\n",
    " \n",
    "    ########################\n",
    "    # print average results\n",
    "    ######################## \n",
    "    print('ACC={:.2f}+/-{:.2f}, ECE={:.2f}+/-{:.2f}, NLL={:.2f}+/-{:.2f}'.format(\n",
    "        np.mean(accs), np.std(accs), np.mean(eces), np.std(eces), np.mean(ces), np.std(ces)))\n",
    "\n",
    "    if with_ens:\n",
    "        ########################\n",
    "        # results for ensemble\n",
    "        ########################  \n",
    "        ens_probs = np.mean(all_probs, axis=0)\n",
    "        ens_preds = np.argmax(ens_probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, ens_preds, ens_probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(ens_probs), torch.from_numpy(labels)).item()\n",
    "        ce = log_loss(labels,ens_probs)\n",
    "\n",
    "        print(30*'-')\n",
    "        print('DEEP ENSEMBLES:')\n",
    "        print('ACC={:.2f}, ECE={:.2f}, NLL={:.2f}'.format(100*test_acc,100*e,100*ce))\n",
    "        \n",
    "    mtrcs = [np.mean(accs), np.mean(eces), np.mean(ces), \n",
    "             np.std(accs),  np.std(eces),  np.std(ces)]\n",
    "\n",
    "    if with_ens:\n",
    "        return mtrcs, [100*test_acc, 100*e, 100*ce]\n",
    "    return mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e366dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_multi_head(dataset=None, model_name='convnext', method='4lmh', n_bins=15, nh=2):\n",
    "    assert dataset is not None\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    # reproducibility\n",
    "    seed=0\n",
    "    set_seed(seed, use_cuda)\n",
    "    if model_name in ['convnext', 'swin'] :\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    assert dataset in ['chaoyang', 'kvasir', 'pathmnist']\n",
    "    \n",
    "\n",
    "    if dataset=='pathmnist':\n",
    "        tg_size = 28 if model_name !='convnext' else 32\n",
    "        test_loader = get_medmnist_test_loader(dataset, batch_size=128, num_workers=6, tg_size=tg_size)\n",
    "        class_names = list(medmnist.INFO[dataset]['label'].keys())\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "    else:\n",
    "        data_path = osp.join('data', dataset)\n",
    "        csv_test = osp.join('data', 'test_'+dataset+'.csv')\n",
    "        tg_size = 224,224   \n",
    "        test_loader  = get_class_test_loader(csv_test, data_path, tg_size, batch_size=64, num_workers=6)\n",
    "        num_classes = len(test_loader.dataset.classes)\n",
    "        class_names = ['C{}_probs'.format(i) for i in range(num_classes)]\n",
    "\n",
    "    \n",
    "    load_path = osp.join('experiments', dataset, method)\n",
    "    if '2h' in method: nh = 2\n",
    "    elif '4h' in method: nh = 4\n",
    "    else: return 'need multi-head model here'\n",
    "    \n",
    "    if model_name=='convnext':\n",
    "        load_path_this = osp.join(load_path, 'cnx_f')\n",
    "    elif model_name=='resnet50':\n",
    "        load_path_this = osp.join(load_path, 'r50_f')\n",
    "    elif model_name=='swin':\n",
    "        load_path_this = osp.join(load_path, 'swt_f')\n",
    "\n",
    "    ########################\n",
    "    # results for multi-head\n",
    "    ########################\n",
    "    model = get_arch(model_name, num_classes, n_heads=nh)\n",
    "    checkpoint_list = [osp.join(load_path_this + str(i), 'model_checkpoint.pth') for i in [0, 1, 2, 3, 4]]\n",
    "    states = [torch.load(c,  map_location=device) for c in checkpoint_list]\n",
    "    all_probs = []\n",
    "    # Do inference on val data\n",
    "    with torch.inference_mode():\n",
    "        for i in range(len(states)):\n",
    "            state=states[i]        \n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "            probs, labels = test_cls_multihead(model, test_loader, device)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    ece = MulticlassCalibrationError(num_classes=num_classes, n_bins=15, norm='l1')\n",
    "\n",
    "    \n",
    "    accs, eces, ces= [],[],[]\n",
    "    for probs in all_probs:\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        test_auc, test_f1, test_acc, test_auc_all, test_f1_all = evaluate_cls(labels, preds, probs, \n",
    "                                                                              print_conf=False)\n",
    "        e = ece(torch.from_numpy(probs), torch.from_numpy(labels)).item()\n",
    "        ce = log_loss(labels,probs)                \n",
    "        accs.append(100*test_acc)\n",
    "        eces.append(100*e)\n",
    "        ces.append(100*ce)\n",
    "        \n",
    "    ########################\n",
    "    # print average results\n",
    "    ######################## \n",
    "    print('ACC={:.2f}+/-{:.2f}, ECE={:.2f}+/-{:.2f}, NLL={:.2f}+/-{:.2f}'.format(\n",
    "    np.mean(accs), np.std(accs), np.mean(eces), np.std(eces), np.mean(ces), np.std(ces)))\n",
    "    \n",
    "    mtrcs = [np.mean(accs), np.mean(eces), np.mean(ces), \n",
    "             np.std(accs),  np.std(eces),  np.std(ces)]\n",
    "    return mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f8245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(dataset, model_name):\n",
    "    metrcs = dict()\n",
    "    print(60*'=')\n",
    "    print('Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "\n",
    "    metrcs['sl1h'], metrcs['ens'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, with_ens=True)\n",
    "\n",
    "    # LS\n",
    "    print('\\n')\n",
    "    print(60*'=')\n",
    "    print('LS gamma=0.05: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['ls_005'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='ls_005', with_ens=False)\n",
    "\n",
    "    # MbLS\n",
    "    print('\\n')\n",
    "    print(60*'=')\n",
    "    print('MbLS m=6: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['mbls_6'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='mbls_6', with_ens=False)\n",
    "    \n",
    "    # MIXUP\n",
    "    print('\\n')   \n",
    "    print(60*'=')\n",
    "    print('MixUp gamma=0.2: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['mxp_02'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='mxp_02', with_ens=False)\n",
    "\n",
    "    # DCA\n",
    "    print('\\n')   \n",
    "    print(60*'=')\n",
    "    print('DCA: Single Head (avg) and Ensembles')\n",
    "    print(60*'=')\n",
    "    metrcs['dca'] = \\\n",
    "    print_results_multi_fold(dataset, model_name, method='dca', with_ens=False)\n",
    "\n",
    "    # 2hsl\n",
    "    print('\\n') \n",
    "    print(60*'=')\n",
    "    print('2hsl')\n",
    "    print(60*'=')\n",
    "    metrcs['2hsl'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='2hsl')\n",
    "\n",
    "    # 2hml\n",
    "    print(60*'*')\n",
    "    print('2hml')\n",
    "    print(60*'*')\n",
    "    metrcs['2hml'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='2hml')\n",
    "\n",
    "    # 4hml   \n",
    "    print(60*'*')\n",
    "    print('4hml')\n",
    "    print(60*'*')\n",
    "    metrcs['4hml'] = \\\n",
    "    print_results_multi_head(dataset, model_name, method='4hml')\n",
    "    \n",
    "    return metrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e28407df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows(col_model_dict, col1, col2, col3, col4, s1, s2, s3, strings):\n",
    "    sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings\n",
    "    a, b, c = 0, 1, 2\n",
    "    x, y, z = 3, 4, 5\n",
    "    sl1h_str=sl1h_str.replace(col1, '{:.2f}'.format(col_model_dict['sl1h'][a]))\n",
    "    sl1h_str=sl1h_str.replace(col2, '{:.2f}'.format(col_model_dict['sl1h'][b]))\n",
    "    sl1h_str=sl1h_str.replace(col3,  '{:.2f}'.format(col_model_dict['sl1h'][c]))\n",
    "    sl1h_str=sl1h_str.replace(col4,  '{:.1f}'.format(col_model_dict['sl1h'][-1]))\n",
    "    sl1h_str=sl1h_str.replace(s1, '{:.2f}'.format(col_model_dict['sl1h'][x]))\n",
    "    sl1h_str=sl1h_str.replace(s2, '{:.2f}'.format(col_model_dict['sl1h'][y]))\n",
    "    sl1h_str=sl1h_str.replace(s3,  '{:.2f}'.format(col_model_dict['sl1h'][z]))\n",
    "    \n",
    "    DE_str=DE_str.replace(col1, '{:.2f}'.format(col_model_dict['ens'][a]))\n",
    "    DE_str=DE_str.replace(col2, '{:.2f}'.format(col_model_dict['ens'][b]))\n",
    "    DE_str=DE_str.replace(col3,  '{:.2f}'.format(col_model_dict['ens'][c]))\n",
    "    DE_str=DE_str.replace(col4,  '{:.1f}'.format(col_model_dict['ens'][-1]))\n",
    "\n",
    "    LS_str=LS_str.replace(col1, '{:.2f}'.format(col_model_dict['ls_005'][a]))\n",
    "    LS_str=LS_str.replace(col2, '{:.2f}'.format(col_model_dict['ls_005'][b]))\n",
    "    LS_str=LS_str.replace(col3,  '{:.2f}'.format(col_model_dict['ls_005'][c]))\n",
    "    LS_str=LS_str.replace(col4,  '{:.1f}'.format(col_model_dict['ls_005'][-1]))\n",
    "    LS_str=LS_str.replace(s1, '{:.2f}'.format(col_model_dict['ls_005'][x]))\n",
    "    LS_str=LS_str.replace(s2, '{:.2f}'.format(col_model_dict['ls_005'][y]))\n",
    "    LS_str=LS_str.replace(s3,  '{:.2f}'.format(col_model_dict['ls_005'][z]))    \n",
    "\n",
    "    MbLS_str=MbLS_str.replace(col1, '{:.2f}'.format(col_model_dict['mbls_6'][a]))\n",
    "    MbLS_str=MbLS_str.replace(col2, '{:.2f}'.format(col_model_dict['mbls_6'][b]))\n",
    "    MbLS_str=MbLS_str.replace(col3,  '{:.2f}'.format(col_model_dict['mbls_6'][c]))\n",
    "    MbLS_str=MbLS_str.replace(col4,  '{:.1f}'.format(col_model_dict['mbls_6'][-1]))\n",
    "    MbLS_str=MbLS_str.replace(s1, '{:.2f}'.format(col_model_dict['mbls_6'][x]))\n",
    "    MbLS_str=MbLS_str.replace(s2, '{:.2f}'.format(col_model_dict['mbls_6'][y]))\n",
    "    MbLS_str=MbLS_str.replace(s3,  '{:.2f}'.format(col_model_dict['mbls_6'][z]))   \n",
    "    \n",
    "    Mxp_str=Mxp_str.replace(col1, '{:.2f}'.format(col_model_dict['mxp_02'][a]))\n",
    "    Mxp_str=Mxp_str.replace(col2, '{:.2f}'.format(col_model_dict['mxp_02'][b]))\n",
    "    Mxp_str=Mxp_str.replace(col3,  '{:.2f}'.format(col_model_dict['mxp_02'][c]))\n",
    "    Mxp_str=Mxp_str.replace(col4,  '{:.1f}'.format(col_model_dict['mxp_02'][-1]))\n",
    "    Mxp_str=Mxp_str.replace(s1, '{:.2f}'.format(col_model_dict['mxp_02'][x]))\n",
    "    Mxp_str=Mxp_str.replace(s2, '{:.2f}'.format(col_model_dict['mxp_02'][y]))\n",
    "    Mxp_str=Mxp_str.replace(s3,  '{:.2f}'.format(col_model_dict['mxp_02'][z]))   \n",
    "    \n",
    "    DCA_str=DCA_str.replace(col1, '{:.2f}'.format(col_model_dict['dca'][a]))\n",
    "    DCA_str=DCA_str.replace(col2, '{:.2f}'.format(col_model_dict['dca'][b]))\n",
    "    DCA_str=DCA_str.replace(col3,  '{:.2f}'.format(col_model_dict['dca'][c]))\n",
    "    DCA_str=DCA_str.replace(col4,  '{:.1f}'.format(col_model_dict['dca'][-1]))\n",
    "    DCA_str=DCA_str.replace(s1, '{:.2f}'.format(col_model_dict['dca'][x]))\n",
    "    DCA_str=DCA_str.replace(s2, '{:.2f}'.format(col_model_dict['dca'][y]))\n",
    "    DCA_str=DCA_str.replace(s3,  '{:.2f}'.format(col_model_dict['dca'][z]))   \n",
    "    \n",
    "    h2sl_str=h2sl_str.replace(col1, '{:.2f}'.format(col_model_dict['2hsl'][a]))\n",
    "    h2sl_str=h2sl_str.replace(col2, '{:.2f}'.format(col_model_dict['2hsl'][b]))\n",
    "    h2sl_str=h2sl_str.replace(col3,  '{:.2f}'.format(col_model_dict['2hsl'][c]))\n",
    "    h2sl_str=h2sl_str.replace(col4,  '{:.1f}'.format(col_model_dict['2hsl'][-1]))\n",
    "    h2sl_str=h2sl_str.replace(s1, '{:.2f}'.format(col_model_dict['2hsl'][x]))\n",
    "    h2sl_str=h2sl_str.replace(s2, '{:.2f}'.format(col_model_dict['2hsl'][y]))\n",
    "    h2sl_str=h2sl_str.replace(s3,  '{:.2f}'.format(col_model_dict['2hsl'][z]))  \n",
    "    \n",
    "    h2ml_str=h2ml_str.replace(col1, '{:.2f}'.format(col_model_dict['2hml'][a]))\n",
    "    h2ml_str=h2ml_str.replace(col2, '{:.2f}'.format(col_model_dict['2hml'][b]))\n",
    "    h2ml_str=h2ml_str.replace(col3,  '{:.2f}'.format(col_model_dict['2hml'][c]))\n",
    "    h2ml_str=h2ml_str.replace(col4,  '{:.1f}'.format(col_model_dict['2hml'][-1]))\n",
    "    h2ml_str=h2ml_str.replace(s1, '{:.2f}'.format(col_model_dict['2hml'][x]))\n",
    "    h2ml_str=h2ml_str.replace(s2, '{:.2f}'.format(col_model_dict['2hml'][y]))\n",
    "    h2ml_str=h2ml_str.replace(s3,  '{:.2f}'.format(col_model_dict['2hml'][z]))\n",
    "    \n",
    "    h4ml_str=h4ml_str.replace(col1, '{:.2f}'.format(col_model_dict['4hml'][a]))\n",
    "    h4ml_str=h4ml_str.replace(col2, '{:.2f}'.format(col_model_dict['4hml'][b]))\n",
    "    h4ml_str=h4ml_str.replace(col3,  '{:.2f}'.format(col_model_dict['4hml'][c])) \n",
    "    h4ml_str=h4ml_str.replace(col4,  '{:.1f}'.format(col_model_dict['4hml'][-1])) \n",
    "    h4ml_str=h4ml_str.replace(s1, '{:.2f}'.format(col_model_dict['4hml'][x]))\n",
    "    h4ml_str=h4ml_str.replace(s2, '{:.2f}'.format(col_model_dict['4hml'][y]))\n",
    "    h4ml_str=h4ml_str.replace(s3,  '{:.2f}'.format(col_model_dict['4hml'][z]))   \n",
    "    \n",
    "    return sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7901fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_acc_ece_nll_combined_ranks(dic):\n",
    "    dic_acc = {key:value[0] for (key,value) in dic.items()} #acc\n",
    "    # False for lower is better, True for higher is better\n",
    "    dic_rank_acc = {key: rank for rank, key in enumerate(sorted(dic_acc, key=dic_acc.get, reverse=True), 1)}\n",
    "       \n",
    "    dic_ece = {key:value[1] for (key,value) in dic.items()}\n",
    "    dic_rank_ece = {key: rank for rank, key in enumerate(sorted(dic_ece, key=dic_ece.get, reverse=False), 1)}\n",
    "\n",
    "    dic_nll = {key:value[2] for (key,value) in dic.items()}\n",
    "    # False for lower is better, True for higher is better\n",
    "    dic_rank_nll = {key: rank for rank, key in enumerate(sorted(dic_nll, key=dic_nll.get, reverse=False), 1)}\n",
    "\n",
    "    \n",
    "    for key in dic:\n",
    "        dic[key].extend([dic_rank_acc[key], dic_rank_ece[key], dic_rank_nll[key],\n",
    "                         np.mean([dic_rank_acc[key], dic_rank_ece[key], dic_rank_nll[key]])])    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76aa17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f240adf",
   "metadata": {},
   "source": [
    "# CHAOYANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f913cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='chaoyang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104adccd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=80.71+/-0.64, ECE=5.79+/-1.75, NLL=53.46+/-3.24\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=82.19, ECE=2.42, NLL=46.64\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=74.81+/-1.88, ECE=2.55+/-0.49, NLL=64.27+/-2.82\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=75.02+/-1.97, ECE=3.26+/-0.97, NLL=63.86+/-4.29\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=76.00+/-1.51, ECE=3.67+/-0.73, NLL=62.72+/-3.00\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=76.17+/-0.87, ECE=5.75+/-1.68, NLL=62.13+/-2.30\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=80.97+/-0.87, ECE=4.36+/-1.88, NLL=51.42+/-2.52\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=80.28+/-0.81, ECE=4.49+/-1.29, NLL=51.86+/-2.17\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=81.13+/-0.82, ECE=3.09+/-0.76, NLL=49.44+/-0.96\n"
     ]
    }
   ],
   "source": [
    "m_r50 = \\\n",
    "print_all(dataset, 'resnet50') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f798f8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=81.91+/-0.46, ECE=6.94+/-1.49, NLL=50.98+/-3.44\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=82.98, ECE=5.21, NLL=46.08\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=79.59+/-0.62, ECE=6.13+/-2.17, NLL=55.65+/-0.79\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=79.53+/-0.93, ECE=2.94+/-0.76, NLL=53.44+/-1.76\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=79.95+/-0.94, ECE=6.20+/-2.28, NLL=55.58+/-1.07\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=78.28+/-0.62, ECE=3.69+/-0.73, NLL=57.78+/-2.28\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=81.94+/-0.29, ECE=4.30+/-1.17, NLL=46.71+/-0.83\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=81.97+/-0.31, ECE=3.66+/-1.15, NLL=45.96+/-0.89\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=82.17+/-0.21, ECE=1.79+/-0.30, NLL=44.73+/-0.51\n"
     ]
    }
   ],
   "source": [
    "m_cvx = \\\n",
    "print_all(dataset, 'convnext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5d8aade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=83.09+/-0.51, ECE=8.73+/-0.45, NLL=52.75+/-1.81\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=83.50, ECE=6.79, NLL=44.80\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=79.76+/-0.73, ECE=3.98+/-0.88, NLL=55.37+/-2.18\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=80.24+/-0.73, ECE=5.06+/-1.65, NLL=54.18+/-2.64\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=80.25+/-0.54, ECE=3.89+/-0.71, NLL=54.62+/-1.87\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=79.12+/-0.79, ECE=7.91+/-1.69, NLL=59.91+/-3.56\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=82.90+/-0.63, ECE=8.20+/-1.76, NLL=54.19+/-8.04\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=82.79+/-0.43, ECE=5.01+/-1.24, NLL=46.12+/-0.88\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=82.89+/-0.44, ECE=4.80+/-1.58, NLL=46.70+/-1.84\n"
     ]
    }
   ],
   "source": [
    "m_swt = \\\n",
    "print_all(dataset, 'swin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f488535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_r18_with_ranks = add_acc_ece_combined_ranks(m_r18)\n",
    "m_r50_with_ranks = add_acc_ece_nll_combined_ranks(m_r50)\n",
    "m_cvx_with_ranks = add_acc_ece_nll_combined_ranks(m_cvx)\n",
    "m_swt_with_ranks = add_acc_ece_nll_combined_ranks(m_swt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec13ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl1h_str  ='\\\\textbf{SL1H}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DE_str    ='\\\\textbf{D-Ens}    & xx1 & xx2 & xx3 & xx4 & xx5 & xx6 & xx7 & xx8 & xx9 & x10 & x11 & x12 \\\\\\\\'\n",
    "LS_str    ='\\\\textbf{LS}       & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "MbLS_str  ='\\\\textbf{MbLS}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "Mxp_str   ='\\\\textbf{MixUp}    & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DCA_str   ='\\\\textbf{DCA}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2sl_str  ='\\\\textbf{2HSL}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2ml_str   ='\\\\textbf{2HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h4ml_str   ='\\\\textbf{4HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d22276ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str]\n",
    "\n",
    "strings = fill_rows(m_r50, 'xx1', 'xx2', 'xx3', 'xx4', 'ss1', 'ss2', 'ss3', strings)\n",
    "strings = fill_rows(m_cvx, 'xx5', 'xx6', 'xx7', 'xx8', 'ss5', 'ss6', 'ss7', strings)\n",
    "strings = fill_rows(m_swt, 'xx9', 'x10', 'x11', 'x12', 'ss9', 's10', 's11', strings)\n",
    "\n",
    "sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c9ec708",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = r'\\caption{Results on the \\textbf{Chaoyang dataset} , with standard deviation for 5 training runs.\\\n",
    "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{chaoyang_dispersion}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "632907f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{sidewaystable}\n",
      "\\renewcommand{\\arraystretch}{1.03}\n",
      "\\setlength\\tabcolsep{1.00pt}\n",
      "\\centering\n",
      "\\caption{Results on the \\textbf{Chaoyang dataset} , with standard deviation for 5 training runs.\\\n",
      "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{chaoyang_dispersion}\n",
      "\\smallskip\n",
      "\\begin{tabular}{c cccc cccc cccc}\n",
      "& \\multicolumn{4}{c}{\\textbf{ResNet50}} & \\multicolumn{4}{c}{\\textbf{ConvNeXt}} & \\multicolumn{4}{c}{\\textbf{Swin-Transformer}} \\\\\n",
      "\\cmidrule(lr){2-5} \\cmidrule(lr){6-9} \\cmidrule(lr){10-13} &  ACC$^\\uparrow$  &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$  &  ACC$^\\uparrow$  &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$    &  ACC$^\\uparrow$ &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$\\\\\n",
      "\\midrule\n",
      "\\textbf{SL1H}     & 80.71$\\pm$0.64 & 5.79$\\pm$1.75 & 53.46$\\pm$3.24 & 6.0 & 81.91$\\pm$0.46 & 6.94$\\pm$1.49 & 50.98$\\pm$3.44 & 6.3 & 83.09$\\pm$0.51 & 8.73$\\pm$0.45 & 52.75$\\pm$1.81 & 5.0 \\\\\n",
      "\\midrule\n",
      "\\textbf{LS}       & 74.81$\\pm$1.88 & 2.55$\\pm$0.49 & 64.27$\\pm$2.82 & 6.7 & 79.59$\\pm$0.62 & 6.13$\\pm$2.17 & 55.65$\\pm$0.79 & 7.3 & 79.76$\\pm$0.73 & 3.98$\\pm$0.88 & 55.37$\\pm$2.18 & 6.0 \\\\\n",
      "\\midrule\n",
      "\\textbf{MbLS}     & 75.02$\\pm$1.97 & 3.26$\\pm$0.97 & 63.86$\\pm$4.29 & 6.7 & 79.53$\\pm$0.93 & 2.94$\\pm$0.76 & 53.44$\\pm$1.76 & 5.3 & 80.24$\\pm$0.73 & 5.06$\\pm$1.65 & 54.18$\\pm$2.64 & 5.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{MixUp}    & 76.00$\\pm$1.51 & 3.67$\\pm$0.73 & 62.72$\\pm$3.00 & 6.3 & 79.95$\\pm$0.94 & 6.20$\\pm$2.28 & 55.58$\\pm$1.07 & 7.0 & 80.25$\\pm$0.54 & 3.89$\\pm$0.71 & 54.62$\\pm$1.87 & 4.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{DCA}      & 76.17$\\pm$0.87 & 5.75$\\pm$1.68 & 62.13$\\pm$2.30 & 6.7 & 78.28$\\pm$0.62 & 3.69$\\pm$0.73 & 57.78$\\pm$2.28 & 7.3 & 79.12$\\pm$0.79 & 7.91$\\pm$1.69 & 59.91$\\pm$3.56 & 8.3 \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\textbf{D-Ens}    & 82.19 & 2.42 & 46.64 & 1.0 & 82.98 & 5.21 & 46.08 & 3.3 & 83.50 & 6.79 & 44.80 & 2.7 \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\textbf{2HSL}     & 80.97$\\pm$0.87 & 4.36$\\pm$1.88 & 51.42$\\pm$2.52 & 4.0 & 81.94$\\pm$0.29 & 4.30$\\pm$1.17 & 46.71$\\pm$0.83 & 4.3 & 82.90$\\pm$0.63 & 8.20$\\pm$1.76 & 54.19$\\pm$8.04 & 5.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{2HML}      & 80.28$\\pm$0.81 & 4.49$\\pm$1.29 & 51.86$\\pm$2.17 & 5.3 & 81.97$\\pm$0.31 & 3.66$\\pm$1.15 & 45.96$\\pm$0.89 & 2.7 & 82.79$\\pm$0.43 & 5.01$\\pm$1.24 & 46.12$\\pm$0.88 & 3.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{4HML}      & 81.13$\\pm$0.82 & 3.09$\\pm$0.76 & 49.44$\\pm$0.96 & 2.3 & 82.17$\\pm$0.21 & 1.79$\\pm$0.30 & 44.73$\\pm$0.51 & 1.3 & 82.89$\\pm$0.44 & 4.80$\\pm$1.58 & 46.70$\\pm$1.84 & 3.3 \\\\\n",
      "\\bottomrule\n",
      "\\\\[-0.25cm]\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print('\\\\begin{sidewaystable}')\n",
    "print('\\\\renewcommand{\\\\arraystretch}{1.03}')\n",
    "print('\\\\setlength\\\\tabcolsep{1.00pt}')\n",
    "print('\\\\centering')\n",
    "print(caption)\n",
    "print('\\\\smallskip')\n",
    "print('\\\\begin{tabular}{c cccc cccc cccc}')\n",
    "print('& \\\\multicolumn{4}{c}{\\\\textbf{ResNet50}} & \\\\multicolumn{4}{c}{\\\\textbf{ConvNeXt}} & \\\\multicolumn{4}{c}{\\\\textbf{Swin-Transformer}} \\\\\\\\')\n",
    "print('\\\\cmidrule(lr){2-5} \\\\cmidrule(lr){6-9} \\\\cmidrule(lr){10-13} &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$  &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$    &  ACC$^\\\\uparrow$ &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$\\\\\\\\')\n",
    "print('\\\\midrule')\n",
    "print(sl1h_str)\n",
    "print('\\midrule')\n",
    "print(LS_str)\n",
    "print('\\midrule')\n",
    "print(MbLS_str)\n",
    "print('\\midrule')\n",
    "print(Mxp_str)\n",
    "print('\\midrule')\n",
    "print(DCA_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(DE_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(h2sl_str)\n",
    "print('\\midrule')\n",
    "print(h2ml_str)\n",
    "print('\\midrule')\n",
    "print(h4ml_str)\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\\\[-0.25cm]')\n",
    "print('\\\\end{tabular}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5947720",
   "metadata": {},
   "source": [
    "# KVASIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0185a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='kvasir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f7d3e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=90.02+/-0.27, ECE=5.18+/-0.52, NLL=35.59+/-2.23\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=90.76, ECE=3.34, NLL=29.74\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=88.24+/-0.56, ECE=6.97+/-1.60, NLL=42.09+/-2.50\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=88.62+/-0.22, ECE=8.55+/-2.06, NLL=43.07+/-2.05\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=87.58+/-0.58, ECE=8.96+/-2.81, NLL=48.88+/-3.67\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=85.27+/-0.89, ECE=4.11+/-0.94, NLL=46.78+/-2.91\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=90.21+/-0.14, ECE=2.63+/-0.45, NLL=28.69+/-0.81\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=89.92+/-0.31, ECE=1.49+/-0.28, NLL=28.15+/-0.18\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=90.10+/-0.29, ECE=1.65+/-0.42, NLL=28.01+/-0.87\n"
     ]
    }
   ],
   "source": [
    "m_cvx = \\\n",
    "print_all(dataset, 'convnext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "796561c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=89.87+/-0.18, ECE=6.32+/-0.24, NLL=41.88+/-1.65\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=90.76, ECE=3.83, NLL=32.09\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=88.13+/-0.46, ECE=14.63+/-1.99, NLL=53.96+/-2.54\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=88.20+/-0.65, ECE=16.92+/-1.05, NLL=57.48+/-2.87\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=87.60+/-0.50, ECE=10.28+/-2.41, NLL=50.69+/-2.65\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=87.14+/-0.64, ECE=3.84+/-0.76, NLL=40.50+/-2.38\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=89.76+/-0.27, ECE=4.52+/-0.93, NLL=34.34+/-3.15\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=90.05+/-0.40, ECE=3.62+/-0.78, NLL=31.37+/-1.97\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=89.99+/-0.25, ECE=2.22+/-0.53, NLL=30.02+/-1.10\n"
     ]
    }
   ],
   "source": [
    "m_r50 = \\\n",
    "print_all(dataset, 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2741ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=90.07+/-0.43, ECE=5.81+/-0.72, NLL=38.01+/-3.61\n",
      "------------------------------\n",
      "DEEP ENSEMBLES:\n",
      "ACC=90.53, ECE=3.94, NLL=29.36\n",
      "\n",
      "\n",
      "============================================================\n",
      "LS gamma=0.05: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=88.74+/-0.68, ECE=9.20+/-1.77, NLL=43.46+/-2.20\n",
      "\n",
      "\n",
      "============================================================\n",
      "MbLS m=6: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=89.15+/-0.49, ECE=8.19+/-0.45, NLL=41.85+/-1.70\n",
      "\n",
      "\n",
      "============================================================\n",
      "MixUp gamma=0.2: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=89.23+/-0.32, ECE=2.11+/-0.25, NLL=35.52+/-1.36\n",
      "\n",
      "\n",
      "============================================================\n",
      "DCA: Single Head (avg) and Ensembles\n",
      "============================================================\n",
      "ACC=87.62+/-0.82, ECE=4.38+/-1.62, NLL=38.44+/-1.16\n",
      "\n",
      "\n",
      "============================================================\n",
      "2hsl\n",
      "============================================================\n",
      "ACC=90.40+/-0.17, ECE=3.65+/-0.67, NLL=29.14+/-1.31\n",
      "************************************************************\n",
      "2hml\n",
      "************************************************************\n",
      "ACC=90.19+/-0.33, ECE=2.73+/-0.64, NLL=28.66+/-1.31\n",
      "************************************************************\n",
      "4hml\n",
      "************************************************************\n",
      "ACC=90.00+/-0.32, ECE=1.82+/-0.35, NLL=27.96+/-0.87\n"
     ]
    }
   ],
   "source": [
    "m_swt = \\\n",
    "print_all(dataset, 'swin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9d950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_r50_with_ranks = add_acc_ece_nll_combined_ranks(m_r50)\n",
    "m_cvx_with_ranks = add_acc_ece_nll_combined_ranks(m_cvx)\n",
    "m_swt_with_ranks = add_acc_ece_nll_combined_ranks(m_swt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb8f6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl1h_str  ='\\\\textbf{SL1H}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DE_str    ='\\\\textbf{D-Ens}    & xx1 & xx2 & xx3 & xx4 & xx5 & xx6 & xx7 & xx8 & xx9 & x10 & x11 & x12 \\\\\\\\'\n",
    "LS_str    ='\\\\textbf{LS}       & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "MbLS_str  ='\\\\textbf{MbLS}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "Mxp_str   ='\\\\textbf{MixUp}    & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "DCA_str   ='\\\\textbf{DCA}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2sl_str  ='\\\\textbf{2HSL}     & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h2ml_str   ='\\\\textbf{2HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'\n",
    "h4ml_str   ='\\\\textbf{4HML}      & xx1$\\pm$ss1 & xx2$\\pm$ss2 & xx3$\\pm$ss3 & xx4 & xx5$\\pm$ss5 & xx6$\\pm$ss6 & xx7$\\pm$ss7 & xx8 & xx9$\\pm$ss9 & x10$\\pm$s10 & x11$\\pm$s11 & x12 \\\\\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d84294e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str]\n",
    "\n",
    "strings = fill_rows(m_r50, 'xx1', 'xx2', 'xx3', 'xx4', 'ss1', 'ss2', 'ss3', strings)\n",
    "strings = fill_rows(m_cvx, 'xx5', 'xx6', 'xx7', 'xx8', 'ss5', 'ss6', 'ss7', strings)\n",
    "strings = fill_rows(m_swt, 'xx9', 'x10', 'x11', 'x12', 'ss9', 's10', 's11', strings)\n",
    "\n",
    "sl1h_str, DE_str, LS_str, MbLS_str, Mxp_str, DCA_str, h2sl_str, h2ml_str, h4ml_str = strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = r'\\caption{Results on the \\textbf{Kvasir dataset} , with standard deviation for 5 training runs.\\\n",
    "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{kvasir_dispersion}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8b8e8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\bigskip\\bigskip  % provide some separation between the two tables\n",
      "\\caption{Results on the \\textbf{Kvasir dataset} , with standard deviation for 5 training runs.\\\n",
      "For each model, \\unl{\\textbf{best}} and \\textbf{second best} ranks are marked.}\\label{kvasir_dispersion}\n",
      "\\smallskip\n",
      "\\smallskip\n",
      "\\begin{tabular}{c cccc cccc cccc}\n",
      "& \\multicolumn{4}{c}{\\textbf{ResNet50}} & \\multicolumn{4}{c}{\\textbf{ConvNeXt}} & \\multicolumn{4}{c}{\\textbf{Swin-Transformer}} \\\\\n",
      "\\cmidrule(lr){2-5} \\cmidrule(lr){6-9} \\cmidrule(lr){10-13} &  ACC$^\\uparrow$  &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$  &  ACC$^\\uparrow$  &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$    &  ACC$^\\uparrow$ &  ECE$_\\downarrow$  &  NLL$_\\downarrow$    &  Rank$_\\downarrow$\\\\\n",
      "\\midrule\n",
      "\\textbf{SL1H}     & 89.87$\\pm$0.18 & 6.32$\\pm$0.24 & 41.88$\\pm$1.65 & 5.3 & 90.02$\\pm$0.27 & 5.18$\\pm$0.52 & 35.59$\\pm$2.23 & 5.0 & 90.07$\\pm$0.43 & 5.81$\\pm$0.72 & 38.01$\\pm$3.61 & 5.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{LS}       & 88.13$\\pm$0.46 & 14.63$\\pm$1.99 & 53.96$\\pm$2.54 & 7.7 & 88.24$\\pm$0.56 & 6.97$\\pm$1.60 & 42.09$\\pm$2.50 & 6.7 & 88.74$\\pm$0.68 & 9.20$\\pm$1.77 & 43.46$\\pm$2.20 & 8.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{MbLS}     & 88.20$\\pm$0.65 & 16.92$\\pm$1.05 & 57.48$\\pm$2.87 & 8.0 & 88.62$\\pm$0.22 & 8.55$\\pm$2.06 & 43.07$\\pm$2.05 & 7.0 & 89.15$\\pm$0.49 & 8.19$\\pm$0.45 & 41.85$\\pm$1.70 & 7.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{MixUp}    & 87.60$\\pm$0.50 & 10.28$\\pm$2.41 & 50.69$\\pm$2.65 & 7.3 & 87.58$\\pm$0.58 & 8.96$\\pm$2.81 & 48.88$\\pm$3.67 & 8.7 & 89.23$\\pm$0.32 & 2.11$\\pm$0.25 & 35.52$\\pm$1.36 & 4.3 \\\\\n",
      "\\midrule\n",
      "\\textbf{DCA}      & 87.14$\\pm$0.64 & 3.84$\\pm$0.76 & 40.50$\\pm$2.38 & 6.0 & 85.27$\\pm$0.89 & 4.11$\\pm$0.94 & 46.78$\\pm$2.91 & 7.3 & 87.62$\\pm$0.82 & 4.38$\\pm$1.62 & 38.44$\\pm$1.16 & 7.3 \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\textbf{D-Ens}    & 90.76 & 3.83 & 32.09 & 2.3 & 90.76 & 3.34 & 29.74 & 3.0 & 90.53 & 3.94 & 29.36 & 3.3 \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\textbf{2HSL}     & 89.76$\\pm$0.27 & 4.52$\\pm$0.93 & 34.34$\\pm$3.15 & 4.7 & 90.21$\\pm$0.14 & 2.63$\\pm$0.45 & 28.69$\\pm$0.81 & 2.7 & 90.40$\\pm$0.17 & 3.65$\\pm$0.67 & 29.14$\\pm$1.31 & 3.0 \\\\\n",
      "\\midrule\n",
      "\\textbf{2HML}      & 90.05$\\pm$0.40 & 3.62$\\pm$0.78 & 31.37$\\pm$1.97 & 2.0 & 89.92$\\pm$0.31 & 1.49$\\pm$0.28 & 28.15$\\pm$0.18 & 2.7 & 90.19$\\pm$0.33 & 2.73$\\pm$0.64 & 28.66$\\pm$1.31 & 2.7 \\\\\n",
      "\\midrule\n",
      "\\textbf{4HML}      & 89.99$\\pm$0.25 & 2.22$\\pm$0.53 & 30.02$\\pm$1.10 & 1.7 & 90.10$\\pm$0.29 & 1.65$\\pm$0.42 & 28.01$\\pm$0.87 & 2.0 & 90.00$\\pm$0.32 & 1.82$\\pm$0.35 & 27.96$\\pm$0.87 & 2.3 \\\\\n",
      "\\bottomrule\n",
      "\\\\[-0.25cm]\n",
      "\\end{tabular}\n",
      "\\end{sidewaystable}\n"
     ]
    }
   ],
   "source": [
    "print('\\\\bigskip\\\\bigskip  % provide some separation between the two tables')\n",
    "print(caption)\n",
    "print('\\\\smallskip')\n",
    "print('\\\\smallskip')\n",
    "print('\\\\begin{tabular}{c cccc cccc cccc}')\n",
    "print('& \\\\multicolumn{4}{c}{\\\\textbf{ResNet50}} & \\\\multicolumn{4}{c}{\\\\textbf{ConvNeXt}} & \\\\multicolumn{4}{c}{\\\\textbf{Swin-Transformer}} \\\\\\\\')\n",
    "print('\\\\cmidrule(lr){2-5} \\\\cmidrule(lr){6-9} \\\\cmidrule(lr){10-13} &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$  &  ACC$^\\\\uparrow$  &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$    &  ACC$^\\\\uparrow$ &  ECE$_\\\\downarrow$  &  NLL$_\\\\downarrow$    &  Rank$_\\\\downarrow$\\\\\\\\')\n",
    "print('\\\\midrule')\n",
    "print(sl1h_str)\n",
    "print('\\midrule')\n",
    "print(LS_str)\n",
    "print('\\midrule')\n",
    "print(MbLS_str)\n",
    "print('\\midrule')\n",
    "print(Mxp_str)\n",
    "print('\\midrule')\n",
    "print(DCA_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(DE_str)\n",
    "print('\\midrule')\n",
    "print('\\midrule')\n",
    "print(h2sl_str)\n",
    "print('\\midrule')\n",
    "print(h2ml_str)\n",
    "print('\\midrule')\n",
    "print(h4ml_str)\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\\\[-0.25cm]')\n",
    "print('\\\\end{tabular}')\n",
    "print('\\\\end{sidewaystable}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
